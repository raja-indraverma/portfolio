<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Projects</title>
  <link rel="stylesheet" href="styleProjects.css">
</head>
<body>
  <div class="container">
    

    <section>
      <h1>Chat-PDF</h2>
      
        <a href="https://github.com/raja-indraverma/chat-PDF" target="_blank">GitHub Link</a><br>
        This application is a Streamlit-based web interface that allows users to interact with PDF documents by uploading them and asking questions about their content. It leverages Google Generative AI models for embedding generation and conversational responses, alongside a FAISS vector store for semantic search. Here's a breakdown of its technical working:
        <div>
        <img src="assets/psf_reader2.png">
        <h3>1. User Interaction via Streamlit:</h3>
        <p>
            <strong>Front-end:</strong> The app uses Streamlit to create an intuitive interface:
        </p>
        <ul>
            <li>A text input box for user questions.</li>
            <li>A file uploader for multiple PDF files.</li>
            <li>A submit button to process uploaded PDFs.</li>
        </ul>
        <p>
            <strong>Sidebar:</strong> The menu options include uploading PDF files and triggering the processing pipeline.
        </p>
        <h3>2. Core Functionalities:</h3>
        <p><strong>Text Extraction:</strong></p>
        <ul>
            <li>The <code>PyPDF2.PdfReader</code> library reads the content of uploaded PDF files.</li>
            <li>Extracted text from all pages of each PDF is concatenated into a single string.</li>
        </ul>
        <h4>Chunking the Text:</h4>
        <ul>
            <li>The <code>RecursiveCharacterTextSplitter</code> from LangChain divides the extracted text into chunks of size 10,000 characters with 1,000 characters overlap.</li>
            <li>This ensures semantic continuity across chunks during embeddings and search.</li>
        </ul>
        <h4>Semantic Search with FAISS:</h4>
        <ul>
            <li><strong>Vector Store Creation:</strong> Text chunks are embedded into vector representations using the <code>GoogleGenerativeAIEmbeddings</code> with the <code>embedding-001</code> model. These embeddings are indexed using FAISS, enabling fast and scalable similarity-based searches.</li>
            <li>The vector store is saved locally for reuse, preventing the need to recompute embeddings for the same documents.</li>
        </ul>
        <h4>Similarity Search:</h4>
        <ul>
            <li>When the user poses a question, the stored embeddings are queried for the most relevant chunks using similarity search.</li>
            <li>The top matching chunks are retrieved for answering the question.</li>
        </ul>
        <h4>Conversational Response Generation:</h4>
        <ul>
            <li><strong>Prompt Design:</strong> A custom prompt is used to guide the conversational model. It ensures detailed answers are extracted from the provided context and avoids incorrect answers by acknowledging when the context doesn't have relevant information.</li>
            <li><strong>Model Usage:</strong> The <code>Gemini-pro</code> model is used as the conversational AI.</li>
            <li><strong>Chain Loading:</strong> The <code>load_qa_chain</code> function constructs the QA pipeline with the prompt template, context, and question.</li>
        </ul>
        
        <h3>Key Technical Components:</h3>
        <table>
            <thead>
                <tr>
                    <th>Feature</th>
                    <th>Technology/Library</th>
                    <th>Purpose</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Front-end</td>
                    <td>Streamlit</td>
                    <td>User interface for interaction</td>
                </tr>
                <tr>
                    <td>PDF Reading</td>
                    <td>PyPDF2</td>
                    <td>Text extraction from PDF files</td>
                </tr>
                <tr>
                    <td>Text Chunking</td>
                    <td>LangChain</td>
                    <td>Preparing text for embedding and search</td>
                </tr>
                <tr>
                    <td>Embedding Generation</td>
                    <td>GoogleGenerativeAIEmbeddings</td>
                    <td>Semantic encoding of text chunks</td>
                </tr>
                <tr>
                    <td>Vector Store</td>
                    <td>FAISS</td>
                    <td>Efficient similarity search for context retrieval</td>
                </tr>
                <tr>
                    <td>Conversational AI</td>
                    <td>ChatGoogleGenerativeAI</td>
                    <td>Answer generation using Gemini-pro</td>
                </tr>
                <tr>
                    <td>Environment Management</td>
                    <td>Python, .env</td>
                    <td>Configuring API keys and environmental variables</td>
                </tr>
            </tbody>
        </table>
        <p><strong>Potential Applications:</strong> Document analysis, customer support, and educational use cases.</p>
    </div>

      
    </section>

    

    <footer>
      <a href="index.html">Back to Home</a>
    </footer>
  </div>
</body>
</html>
